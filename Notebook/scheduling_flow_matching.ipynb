{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Union, List \n",
    "import math \n",
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "\n",
    "from diffusers.configuration_utils import ConfigMixin, register_to_config \n",
    "from diffusers.utils import BaseOutput, logging \n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from diffusers.schedulers.scheduling_utils import SchedulerMixin\n",
    "\n",
    "from IPython import embed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FlowMatchEulerDiscreteSchedulerOutput(BaseOutput):\n",
    "\n",
    "    \"\"\" \n",
    "    Output class for scheduler's 'step' function output.\n",
    "\n",
    "    Args:\n",
    "        prev_sample ('torch.FloatTensor' of shape `(batch_size, num_channels, height, width)` for images):\n",
    "            Computed sample `(x_{t-1})` of previous timestep. `prev_sample` should be used as next model input in the \n",
    "            denoising loop.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    prev_sample: torch.FloatTensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidFlowMatchEulerDiscreteScheduler(SchedulerMixin, ConfigMixin):\n",
    "\n",
    "    \"\"\" \n",
    "    Euler scheduler.\n",
    "\n",
    "    This model inherits from ['SchedulerMixin'] and ['ConfigMixin']. Check the superclass documentation for the generic \n",
    "    methods the library implements for all schedulers such as loading and saving.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    _compatibles = []\n",
    "    order = 1 \n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(self,\n",
    "                 num_train_timesteps:int = 1000,\n",
    "                 shift: float = 1.0,\n",
    "                 stages: int = 3,\n",
    "                 stage_range: List = [0, 1/3, 2/3, 1],\n",
    "                 gamma: float = 1/3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.timestep_ratios = {}\n",
    "        self.timestep_per_stage = {}\n",
    "        self.sigmas_per_stage = {}\n",
    "        self.start_sigmas = {}\n",
    "        self.end_sigmas = {}\n",
    "        self.ori_start_sigmas = {}\n",
    "\n",
    "        # self.init_sigmas()\n",
    "        self.init_sigmas_for_each_stage()\n",
    "        self.sigma_min = self.sigmas[-1].item()\n",
    "        self.sigma_max = self.sigmas[0].item()\n",
    "        self.gamma = gamma \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Init Sigmas\n",
    "\n",
    "- This method initializes the `timesteps` and `sigmas` attributes of the class, which are essential for managing the progression of training steps and their corresponding scaling factor. \n",
    "The transformation applied to `sigmas` ensures they are appropriately scaled based on the `shift` parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sigmas(self):\n",
    "        \"\"\" \n",
    "        Initialize the global timesteps and sigmas\n",
    "        \"\"\"\n",
    "\n",
    "        num_train_timesteps = self.config.num_train_timesteps     # the total number of training timesteps\n",
    "        shift = self.config.shift                                 # A scaling factor used in the calculation of sigmas.\n",
    "\n",
    "        timesteps = np.linspace(1, num_train_timesteps, num_train_timesteps, dtype=np.float32)     # creates an array of num_train_timesteps evenly spaced values between 1 and num_train_timesteps.\n",
    "        [::-1].copy()  # Reverse the array\n",
    "\n",
    "\n",
    "\n",
    "        timesteps = torch.from_numpy(timesteps).to(dtype=torch.float32)    # convert the numpy array to a PyTorch tensor with float32 data type\n",
    "\n",
    "        sigmas = timesteps / num_train_timesteps                 # normalize the timesteps\n",
    "        sigmas = shift * sigmas / (1 + (shift - 1) * sigmas)     # Applies a transformation to the sigmas using the shift parameter\n",
    "\n",
    "        self.timesteps = sigmas * num_train_timesteps            # scale the sigmas back to the range of timesteps\n",
    "\n",
    "\n",
    "        # initialize this indices\n",
    "        self._step_index = None \n",
    "        self._begin_index = None \n",
    "\n",
    "\n",
    "        # Moves the sigmas tensor to the CPU\n",
    "        self.sigmas = sigmas.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Initialize the  sigmas for each stage \n",
    "\n",
    "- This method initialize the timesteps and sigmas for each stage based on the configuration and calculated ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sigmas_for_each_stage(self):\n",
    "\n",
    "        \"\"\" \n",
    "        init the timesteps for each stage\n",
    "        \"\"\"\n",
    "\n",
    "        self.init_sigmas()     # initialize sigma values\n",
    "\n",
    "        stage_distance = []\n",
    "        stages = self.config.stages \n",
    "        training_steps = self.config.num_train_timesteps \n",
    "        stage_range = self.config.stage_range \n",
    "\n",
    "\n",
    "        # Init the start and end point of each stage \n",
    "        # Loop through stages iterates over each stage \n",
    "        # start and End indices calculate start and end indices for each stage based on `stage_range` and `training_steps`\n",
    "        for i_s in range(stages):\n",
    "            # To decide the start and ends point \n",
    "            start_indices = int(stage_range[i_s] * training_steps)\n",
    "            start_indices = max(start_indices, 0)\n",
    "            \n",
    "            end_indices = int(stage_range[i_s+1] * training_steps)\n",
    "            end_indices = min(end_indices, training_steps)\n",
    "\n",
    "\n",
    "            \n",
    "            start_sigma = self.sigmas[end_indices].item() if end_indices < training_steps else 0.0   # Determines the starting sigma value for the stage \n",
    "            self.ori_start_sigmas[i_s] = start_sigma             # store the starting sigma value in `self.ori_start_sigmas`\n",
    "\n",
    "\n",
    "            # correct sigma: for stages other than the first corrects the sigma value using a formula involving `gamma`.\n",
    "            if i_s != 0:\n",
    "                ori_sigma = 1 - start_sigma\n",
    "                gamma = self.config.gamma \n",
    "\n",
    "                corrected_sigma = (1 / (math.sqrt(1 + (1 / gamma)) * (1 - ori_sigma) + ori_sigma)) * ori_sigma\n",
    "\n",
    "                start_sigma = 1 - corrected_sigma\n",
    "\n",
    "\n",
    "\n",
    "        # Determine the ratio of each stage according to flow length \n",
    "        tot_distance = sum(stage_distance)      # calculate the total distance by sum `stage_distance`\n",
    "\n",
    "\n",
    "        # stage ratio: Determine the start and end ratio for each stage based on `stage_distance`\n",
    "        for i_s in range(stages):\n",
    "            if i_s == 0:\n",
    "                start_ratio = 0.0 \n",
    "\n",
    "\n",
    "            else:\n",
    "                start_ratio = sum(stage_distance[:i_s]) / tot_distance\n",
    "\n",
    "            if i_s == stages - 1:\n",
    "                end_ratio = 1.0 \n",
    "\n",
    "\n",
    "            else:\n",
    "                end_ratio = sum(stage_distance[:i_s+1]) / tot_distance\n",
    "\n",
    "\n",
    "            self.timestep_ratios[i_s] = (start_ratio, end_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Determine the tiemsteps and sigmas for each stage \n",
    "        # Timesteps and sigmas: For each stage, calculates the timesteps and sigmas then stores them in `self.timestep_per_stage` and `self.sigmas_per_stage`\n",
    "        for i_s in range(stages):\n",
    "            timestep_ratio = self.timestep_ratios[i_s]\n",
    "            timestep_max = self.timestep[int(timestep_ratio[0] * training_steps)]\n",
    "            timestep_min = self.timesteps[min(int(timestep_ratio[1] * training_steps), training_steps - 1)]\n",
    "            timesteps = np.linspace(\n",
    "                timestep_max, timestep_min, training_steps + 1\n",
    "            )\n",
    "\n",
    "            self.timestep_per_stage[i_s] = torch.from_numpy(timesteps[:-1])\n",
    "            stage_sigmas = np.linspace(\n",
    "                1, 0, training_steps + 1\n",
    "            )\n",
    "\n",
    "            self.sigmas_per_stage[i_s] = torch.from_numpy(stage_sigmas[:-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3 Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def step_index(self):\n",
    "        \"\"\" \n",
    "        The index counter for current timestep. It will increase 1 after each scheduler step.\n",
    "        \"\"\"\n",
    "        return self._step_index\n",
    "    \n",
    "\n",
    "@property\n",
    "def begin_index(self):\n",
    "        \"\"\" \n",
    "        The index for the first timestep. It should be set from pipeline with `set_begin_index` method.\n",
    "        \"\"\"\n",
    "        return self._begin_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_begin_index(self, \n",
    "                        begin_index:int = 0):\n",
    "        \n",
    "        \"\"\" \n",
    "        Sets the begin index for the scheduler. This function should be run from pipeline before the inference.\n",
    "\n",
    "        Args:\n",
    "            begin_index ('int'):\n",
    "                The begin index for the scheduler.\n",
    "        \"\"\"\n",
    "\n",
    "        self._begin_index = begin_index\n",
    "\n",
    "\n",
    "def sigma_to_t(self, sigma):\n",
    "    return sigma * self.config.num_train_timesteps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Set Timesteps\n",
    "\n",
    "- This method sets the timesteps and sigma values for a specific stage, preparing them for the inference process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_timesteps(self, num_inference_steps: int, stage_index: int, device: Union[str, torch.device] = None):\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "            Setting the timesteps and sigmas for each stage \n",
    "        \"\"\"\n",
    "\n",
    "        self.num_inference_steps = num_inference_steps          # Assign `num_inference_steps` to an instance variable \n",
    "        training_steps = self.config.num_train_timesteps        # get the number of training timesteps from the configuration.\n",
    "        self.init_sigmas()                                      # `self.init_sigmas()` to initilize sigma values\n",
    "\n",
    "        stage_timesteps = self.timesteps_per_stage[stage_index]      # Retrives the timesteps for the specified stage\n",
    "        timestep_max = stage_timesteps[0].item()                     # get the maximumn and minimum timesteps for the stage.\n",
    "        timestep_min = stage_timesteps[-1].item()\n",
    "\n",
    "\n",
    "        # Generate Timestep: creates a linerly spaced array of timesteps from `timestep_max` to `timestep_min`\n",
    "        timesteps = np.linspace(\n",
    "            timestep_max, timestep_min, num_inference_steps,\n",
    "        )\n",
    "\n",
    "        # Convert to Tensor: Converts the numpy array to a PyTorch tensor and moves it to the specified device.\n",
    "        self.timesteps = torch.from_numpy(timesteps).to(device=device)\n",
    "\n",
    "        stage_sigmas = self.sigmas_per_stage[stage_index]     # stage sigmas: Retrives the sigma values for the specified stage \n",
    "        sigma_max = stage_sigmas[0].item()                    # Max and Min sigmas: Gets the maximum and  minimum sigma values for the stage.\n",
    "        sigma_min = stage_sigmas[-1].item()\n",
    "\n",
    "\n",
    "\n",
    "        # Generate sigma: Creates a linerly speced array of sigma values from `sigma_max` to `sigma_min`\n",
    "        ratios = np.linspace(\n",
    "            sigma_max, sigma_min, num_inference_steps\n",
    "        )\n",
    "\n",
    "        sigmas = torch.from_numpy(ratios).to(device=device)    # convert to Tensor: converts the numpy array to a Pytorch tensor and moves it to the specified device.\n",
    "        self.sigmas = torch.cat([sigmas, torch.zeros(1, device=sigmas.device)])    # Concatenate zero:  Adds a zero at the end of the sigma tensor\n",
    "\n",
    "        self._step_index = None   # Reset Step index: Reset the internal step index to `None`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Index for Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_for_timestep(self, timestep, schedule_timestep=None):\n",
    "\n",
    "    if schedule_timestep is None:\n",
    "        schedule_timestep = self.timesteps\n",
    "\n",
    "\n",
    "    indices = (schedule_timestep == timestep).nonzero()\n",
    "\n",
    "\n",
    "    # The sigma index that is taken for the **very** first `step`\n",
    "    # is always the second index (or the last index if there is only 1.)\n",
    "    # This may we can ensure we don't accidently skip a sigma in \n",
    "    # case we start in the middle of the denoising schedule (e.g. For image-to-image)\n",
    "    pos = 1 if len(indices) > 1 else 0 \n",
    "\n",
    "    return indices[pos].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_step_index(self, timestep):\n",
    "\n",
    "    if self.begin_index is None:\n",
    "        if isinstance(timestep, torch.Tensor):\n",
    "            timestep = timestep.to(self.timesteps.device)\n",
    "\n",
    "        self._step_index = self.index_for_timestep(timestep)\n",
    "\n",
    "    else:\n",
    "        self._step_index = self._begin_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(\n",
    "        self,\n",
    "        model_output: torch.FloatTensor,\n",
    "        timestep: Union[float, torch.FloatTensor],\n",
    "        sample: torch.FloatTensor,\n",
    "        generator: Optional[torch.Generator] = None,\n",
    "        return_dict: bool = True\n",
    ") -> Union[FlowMatchEulerDiscreteSchedulerOutput, Tuple]:\n",
    "    \n",
    "    \"\"\"\n",
    "        Predict the sample from the previous timestep by reversing the SDE. This function propagates the diffusion\n",
    "        process from the learned model outputs (most often the predicted noise).\n",
    "        Args:\n",
    "            model_output (`torch.FloatTensor`):\n",
    "                The direct output from learned diffusion model.\n",
    "            timestep (`float`):\n",
    "                The current discrete timestep in the diffusion chain.\n",
    "            sample (`torch.FloatTensor`):\n",
    "                A current instance of a sample created by the diffusion process.\n",
    "            generator (`torch.Generator`, *optional*):\n",
    "                A random number generator.\n",
    "            return_dict (`bool`):\n",
    "                Whether or not to return a [`~schedulers.scheduling_euler_discrete.EulerDiscreteSchedulerOutput`] or\n",
    "                tuple.\n",
    "        Returns:\n",
    "            [`~schedulers.scheduling_euler_discrete.EulerDiscreteSchedulerOutput`] or `tuple`:\n",
    "                If return_dict is `True`, [`~schedulers.scheduling_euler_discrete.EulerDiscreteSchedulerOutput`] is\n",
    "                returned, otherwise a tuple is returned where the first element is the sample tensor.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if (\n",
    "        isinstance(timestep, int) or isinstance(timestep, torch.IntTensor) or isinstance(timestep, torch.LongTensor)\n",
    "    ): \n",
    "        \n",
    "        raise ValueError(\n",
    "            (\n",
    "                 \"Passing integer indices (e.g. from `enumerate(timesteps)`) as timesteps to\"\n",
    "                    \" `EulerDiscreteScheduler.step()` is not supported. Make sure to pass\"\n",
    "                    \" one of the `scheduler.timesteps` as a timestep.\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "\n",
    "    if self.step_index is None:\n",
    "        self._step_index = 0 \n",
    "\n",
    "\n",
    "    # Upcast to avoid precision issues when computing prev_sample \n",
    "    sample = sample.to(torch.float32)\n",
    "\n",
    "    sigma = self.sigmas[self.step_index]\n",
    "    sigma_next = self.sigmas[self.step_index + 1]\n",
    "\n",
    "    prev_sample = sample + (sigma_next - sigma) * model_output\n",
    "\n",
    "    # Cast sample back to model compatible dtype \n",
    "    prev_sample = prev_sample.to(model_output.dtype)\n",
    "\n",
    "    # upon completation increase step index by one \n",
    "    self._step_index += 1 \n",
    "\n",
    "    if not return_dict:\n",
    "        return (prev_sample,)\n",
    "    \n",
    "\n",
    "    return FlowMatchEulerDiscreteSchedulerOutput(prev_sample=prev_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __len__(self):\n",
    "    return self.config.num_train_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
