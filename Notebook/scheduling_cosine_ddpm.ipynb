{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import torch \n",
    "\n",
    "\n",
    "\n",
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "from diffusers.utils import BaseOutput\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from diffusers.schedulers.scheduling_utils import SchedulerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 DDPM Scheduler output\n",
    "\n",
    "- DDPM -> Denoising Diffusion Probabilistic Models. \n",
    "<p style=\"color:red\">These models are a type of **generative model** used in machine learning, particularly for tasks like **image generation**.\n",
    "They work by gradually **denoising** a sample from a sample distrubution to match the data distribution, making them effective for generating high-quality image</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `@dataclass`:  The decorator is used to autimatically generate special method like `__init__()` and `__repr__()` for the class, making it easier to create data containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `__repr__()` -> this is the meaning of representation in python. This method is used to define the string representation of an object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hello"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Representation:\n",
    "\n",
    "    def __init__(self, name:str):\n",
    "        self.name = name \n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.name \n",
    "    \n",
    "\n",
    "\n",
    "Representation(name=\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DDPMSchedulerOutput(prev_sample=tensor([2.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class DDPMSchedulerOutput(BaseOutput):\n",
    "\n",
    "    \"\"\" \n",
    "    Output class for the scheduler step function output.\n",
    "\n",
    "    Args:\n",
    "        prev_sample (`torch.Tensor` of shape `(batch_size, num_channels, height, width`) for images):\n",
    "        Computed sample (x_{t-1}) of previous timestep. `prev_sample` should be used as next model input in the \n",
    "        denoising loop.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    prev_sample: torch.Tensor\n",
    "\n",
    "\n",
    "\n",
    "prev_sample = torch.Tensor([2])\n",
    "# print(prev_sample)\n",
    "DDPMSchedulerOutput(prev_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 DDPMS Cosine Scheduler \n",
    "\n",
    "- `register_to_config`: This decorator register the configuration parameters.\n",
    "- `__init__()` method initilizes the scheduler with `scalar` and `s` **parameter** , Computes `_init_alpha_cumprod` and set the `init_noise_sigma`\n",
    "\n",
    "- `_init_alpha_cumprod` method computes the cumulative product of alpha values, adjusting `t` based on the scaler and using cosine function to calculate the values.\n",
    "\n",
    "--------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMCosineScheduler(SchedulerMixin, ConfigMixin):\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(self,\n",
    "                scaler: float = 1.0,\n",
    "                s: float = 0.008\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.s = torch.tensor([s])\n",
    "        self._init_alpha_cumprod = torch.cos(self.s / (1 + self.s) * torch.pi * 0.5) ** 2\n",
    "\n",
    "\n",
    "\n",
    "        # standard deviation of the initial noise distribution \n",
    "        self.init_noise_sigma = 1.0 \n",
    "\n",
    "\n",
    "    def _alpha_cumprod(self, t, device):\n",
    "\n",
    "        if self.scaler > 1: \n",
    "            t = 1 - (1 - t) ** self.scaler \n",
    "\n",
    "\n",
    "\n",
    "        elif self.scaler < 1:\n",
    "            t = t ** self.scaler \n",
    "\n",
    "\n",
    "        alpha_cumprod = torch.cos(\n",
    "            (t + self.s.to(device)) / (1 + self.s.to(device)) * torch.pi * 0.5 \n",
    "        ) ** 2 / self._init_alpha_cumprod.to(device)\n",
    "\n",
    "\n",
    "        return alpha_cumprod.clamp(0.0001, 0.9999)\n",
    "    \n",
    "\n",
    "\n",
    "    def scale_model_input(self,\n",
    "                          sample: torch.Tensor,\n",
    "                          timestep: Optional[int] = None\n",
    "                          ) -> torch.Tensor:\n",
    "        \n",
    "\n",
    "        \"\"\" \n",
    "        Ensures interchangeability with schedulers that need to scale the denoising model input depending on the \n",
    "        current timestep.\n",
    "\n",
    "\n",
    "        Args: \n",
    "            sample (`torch.Tensor`): input sample \n",
    "            timestep (`init`, optional): current timestep \n",
    "\n",
    "\n",
    "        Returns:\n",
    "            `torch.Tensor`: scaled input sample\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        return sample\n",
    "    \n",
    "\n",
    "\n",
    "    def set_timestep(\n",
    "            self,\n",
    "            num_inference_steps: int = None,\n",
    "            timesteps: Optional[List[int]] = None, \n",
    "            device: Union[str, torch.device] = None,\n",
    "    ):\n",
    "        \n",
    "\n",
    "        \"\"\" \n",
    "        Sets the discreate timesteps used for the diffusion chain. Supporting function to be run before inference.\n",
    "\n",
    "        Args:\n",
    "            num_inference_steps (`Dict[float, int]`):\n",
    "                the number of diffusion steps used when generating samples with a pre-trained model. If passed, then \n",
    "                `timesteps` must be `None`. \n",
    "\n",
    "            device (`str` or `torch.device`, optional):\n",
    "                the device to which the timesteps are moved to. {2 / 3: 20, 0.0: 10}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if timesteps is None:\n",
    "            timesteps = torch.linspace(1.0, 0.0, num_inference_steps + 1, device)\n",
    "\n",
    "        \n",
    "        if not isinstance(timesteps, torch.Tensor):\n",
    "            timesteps = torch.Tensor(timesteps).to(device)\n",
    "\n",
    "\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "\n",
    "\n",
    "    # This function is part of the denoising process in a diffusion model, where it computes the next sample in the sequence\n",
    "    # based on the current model output and timestep.\n",
    "    def step(\n",
    "            self,\n",
    "            model_output: torch.Tensor,                 # the output tensor from the model.\n",
    "            timestep: int,                              # the current timestep in the denoising process\n",
    "            sample: torch.Tensor,                       # the current sample tensor\n",
    "            generator: None,                            # A random number generator (optional)\n",
    "            return_dict: bool = True                    # A boolean indicating whether to return a dictionary or a tuple\n",
    "    ) -> Union[DDPMSchedulerOutput, Tuple]:\n",
    "        \n",
    "\n",
    "        # initilize variables \n",
    "        dtype = model_output.dtype\n",
    "        device = model_output.device\n",
    "        t = timestep\n",
    "\n",
    "        prev_t = self.previous_timestep(t)\n",
    "\n",
    "        # Compute Alpha Cumulative Products\n",
    "        alpha_cumprod = self._alpha_cumprod(t, device).view(t.size(0), *[1 for _ in sample.shape[1:]])\n",
    "        alpha_cumprod_prev = self._alpha_cumprod(prev_t, device).view(prev_t.size(0), *[1 for _ in sample.shape[1:]])\n",
    "        alpha = alpha_cumprod / alpha_cumprod_prev\n",
    "\n",
    "        # compute mean\n",
    "        mu = (1.0 / alpha).sqrt() * (sample - (1 - alpha) * model_output / (1 - alpha_cumprod).sqrt())\n",
    "\n",
    "\n",
    "        # Generate Standard Noise and Compute standard Deviation \n",
    "        std_noise = randn_tensor(mu.shape, generator=generator, device=model_output.device, dtype=model_output.dtype)\n",
    "        std = ((1 - alpha) * (1.0 - alpha_cumprod_prev) / (1.0 - alpha_cumprod)).sqrt() * std_noise\n",
    "\n",
    "\n",
    "        # compute preduction \n",
    "        pred = mu + std * (prev_t != 0).float().view(prev_t.size(0), *[1 for _ in sample.shape[1:]])\n",
    "\n",
    "\n",
    "        # return results\n",
    "        if not return_dict:\n",
    "            return (pred.to(dtype),)\n",
    "\n",
    "\n",
    "        return DDPMSchedulerOutput(prev_sample=pred.to(dtype))\n",
    "    \n",
    "\n",
    "\n",
    "    # This functin is typically used in diffusion model to add noise to the amples at each timestep, simulating the forward \n",
    "    # diffusion process.\n",
    "    def add_noise(\n",
    "            self, \n",
    "            original_samples: torch.Tensor,       # the original tensor samples to which noise will be added\n",
    "            noise: torch.Tensor,                  # the noise tensor to be added to the original samples\n",
    "            timesteps: torch.Tensor               # the timesteps tensor indicating the current step in the diffusion process\n",
    "\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "\n",
    "        # initialize variables\n",
    "        device = original_samples.device\n",
    "        dtype = original_samples.dtype\n",
    "\n",
    "\n",
    "\n",
    "        # compute alpha comulative products\n",
    "        alpha_cumprod = self._alpha_cumprod(timesteps, device=device).view(\n",
    "            timesteps.size(0), *[1 for _ in original_samples.shape[1:]]\n",
    "        )\n",
    "\n",
    "        # compute noise samples\n",
    "        noisy_samples = alpha_cumprod.sqrt() * original_samples + (1 - alpha_cumprod).sqrt() * noise \n",
    "\n",
    "        # return noise samples\n",
    "        return noisy_samples.to(dtype=dtype)\n",
    "    \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.config.num_train_tiemsteps \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def previous_timestep(self, timestep):\n",
    "        index = (self.timesteps - timestep[0]).abs().argmin().item()\n",
    "        prev_t = self.timesteps[index + 1][None].extend(timestep.shape[0])\n",
    "        return prev_t\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 _alpha_cumprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if is working\n",
      "tensor([0.3925])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manjusha Kumari\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\configuration_utils.py:140: FutureWarning: Accessing config attribute `scaler` directly via 'DDPMCosineScheduler' object attribute is deprecated. Please access 'scaler' over 'DDPMCosineScheduler's config object instead, e.g. 'scheduler.config.scaler'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    }
   ],
   "source": [
    "class DDPMCosineScheduler(SchedulerMixin, ConfigMixin):\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(self,\n",
    "                scaler: float = 1.0,\n",
    "                s: float = 0.008\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.s = torch.tensor([s])\n",
    "        self._init_alpha_cumprod = torch.cos(self.s / (1 + self.s) * torch.pi * 0.5) ** 2\n",
    "\n",
    "\n",
    "\n",
    "        # standard deviation of the initial noise distribution \n",
    "        self.init_noise_sigma = 1.0 \n",
    "\n",
    "\n",
    "    def _alpha_cumprod(self, t, device):\n",
    "\n",
    "        if self.scaler > 1: \n",
    "            t = 1 - (1 - t) ** self.scaler \n",
    "            print(\"if is working\")\n",
    "\n",
    "\n",
    "\n",
    "        elif self.scaler < 1:\n",
    "            t = t ** self.scaler \n",
    "            print(\"elif is working\")\n",
    "\n",
    "\n",
    "        alpha_cumprod = torch.cos(\n",
    "            (t + self.s.to(device)) / (1 + self.s.to(device)) * torch.pi * 0.5 \n",
    "        ) ** 2 / self._init_alpha_cumprod.to(device)\n",
    "\n",
    "\n",
    "        return alpha_cumprod.clamp(0.0001, 0.9999)\n",
    "    \n",
    "\n",
    "# Example\n",
    "scheduler = DDPMCosineScheduler(scaler=1.2, s=0.01)\n",
    "t = torch.tensor([0.5])\n",
    "device = torch.device('cpu')\n",
    "alpha_cumprod = scheduler._alpha_cumprod(t, device)\n",
    "print(alpha_cumprod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.9990, 0.9980,  ..., 0.0020, 0.0010, 0.0000], device='cuda:0')\n",
      "tensor([0.0000, 0.5000, 1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class DDPMCosineScheduler(SchedulerMixin, ConfigMixin):\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(self,\n",
    "                scaler: float = 1.0,\n",
    "                s: float = 0.008\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.s = torch.tensor([s])\n",
    "        self._init_alpha_cumprod = torch.cos(self.s / (1 + self.s) * torch.pi * 0.5) ** 2\n",
    "\n",
    "\n",
    "\n",
    "        # standard deviation of the initial noise distribution \n",
    "        self.init_noise_sigma = 1.0 \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def set_timesteps(\n",
    "        self,\n",
    "        num_inference_steps: int = None,\n",
    "        timesteps: Optional[List[int]] = None,\n",
    "        device: Union[str, torch.device] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference.\n",
    "\n",
    "        Args:\n",
    "            num_inference_steps (`Dict[float, int]`):\n",
    "                the number of diffusion steps used when generating samples with a pre-trained model. If passed, then\n",
    "                `timesteps` must be `None`.\n",
    "            device (`str` or `torch.device`, optional):\n",
    "                the device to which the timesteps are moved to. {2 / 3: 20, 0.0: 10}\n",
    "        \"\"\"\n",
    "        if timesteps is None:\n",
    "            timesteps = torch.linspace(1.0, 0.0, num_inference_steps + 1, device=device)\n",
    "        if not isinstance(timesteps, torch.Tensor):\n",
    "            timesteps = torch.Tensor(timesteps).to(device)\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage \n",
    "scheduler = DDPMCosineScheduler()\n",
    "num_inference_steps = 1000 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "scheduler.set_timesteps(num_inference_steps=num_inference_steps,\n",
    "                        device=device\n",
    "                        )\n",
    "print(scheduler.timesteps)\n",
    "\n",
    "\n",
    "# set timesteps using a custom list \n",
    "custom_timesteps = [0.0, 0.5, 1.0]\n",
    "scheduler.set_timesteps(timesteps=custom_timesteps, device=device)\n",
    "print(scheduler.timesteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
